* BEFORE TRAINING STARTS AGAIN
  1. [ ] Verify model polarity needs to start working if there are multiple FIRs
  2. [ ] Sparsity/smoothness calculations need to work IN the FIR module (since there could be multiple ones)
  3. 

* KEYWORDS
  1. [ ] Init FIR to rcorr
  2. [ ] Init FIR to zero
  3. [ ] 

* SMALL CORRECTIONS AUDIT LIST
  1. [X] Put proper docstrings on every function in util/
  2. [X] Search for obviously dead code and bury it in the graveyard
  3. [X] Make sure that 1-r is the score to be minimized, not 1/r^2
  4. [X] Repair git commit logging
  5. [ ] IRRITATION: Why doesn't it show the model save filename so I can see which file I just loaded if I forgot?
  6. [ ] IRRITATION: Why doesn't every plotted signal have a legend?
  7. [ ] IRRITATION: Why don't the X (or at least the Y) axes have scales?
  8. [ ] Generic nonlinearity should do smooth scatter plots of multi-input things!
  9. [ ] IRRITATION: Why are the editable text boxes so damn small?
  10. [ ] Remember to invalidate data BELOW the present point on a table-edit callback... and to update the gui to reflect this!
  11. [ ] Replace my nargin checks with "if ~exist('BLAH','var'),"
  12. [ ] Is this line fine with the closures? m.plot_fns{1}.fn = @(stack, xxx) do_plot_channel_vs_time(stack, xxx, m.time, m.output);
  13. [ ] Replace all the 'true' and 'false' arguments with textual flags and varargin that are more descriptive
  14. [ ] Make sure that fitters return specific codes indicating how they terminated
  15. [ ] Pull out repeated code blocks in the fitters (because they are all pretty much the same damn thing over and over again)
  16. [ ] Repair NarfModelpane
          - [ ] Displays model name, training set, test set, and other important info at top of window
	  - [ ] Standardized colors for all module plots
  17. [-] NARF Browser Improvements
          - [X] Scatter plot test/train button
          - [ ] Heat Map current display button	
  18. [ ] Antialiasing problem when saving images
  19. [ ] Make the model run faster by only adding the 'test_set' data at the very end of the fitting process
  20. [ ] Clean up distribution of code before a modelfit
	  - [ ] Function which distributes GIT to workers before enqueing models
	  - [ ] Checks local repository is clean
  21. [ ] MODULE: Standardized single/multi channel gammatone filter
  22. [ ] MODULE: Standardized single/multi channel elliptic filter 
  23. [ ] Plot both test and training data for smooth scatter plots.
  24. [ ] FN: 'set_module_field' (finds module, sets field, so you can mess with things more easily in scripts)
  25. [ ] Add a precompressor keyword which concats log compressor as an extra channel
  26. [ ] Make Concat Second Order Terms work for any higher order nchoosek type stuff
  27. [ ] Provide functions to cover an input space logarithmically with filters
  28. [ ] Add error handling (catch/throw) around EVERY CALL to a user defined function, trigger popup?
  29. [ ] Ensure that no closures of data are being done by methods. Methods should accept the module object as their first argument, not close over anything.
  30. [ ] It's not quite right to have the 'replot' command be part of the the 'plot_popup fn callback'. Needs to be re-thought
  31. [ ] When you click save, it should bring up a 'trainerstring' name so you can customize how the model is saved.
	  Models are currently built using modelnames...but it's plausible that SOME modelnames aren't built that way. They could still come from the GUI or by script.
	  Therefore, there needs to be detection/verification at savetime which checks that the model has the same structure as when it was built.
	  It also needs to insert the NEW model into the database!
  32. [ ] MODULE: Add a module which can pick out a particular dimension from a vector and give it a name as a signal
  33. [ ] MODULE: Build a non-cheating model which extracts envelopes directly from the WAV files using an elliptic or gammatone prefilter
  34. [ ] IRRITATION: Why can't I resize windows?
  35. [ ] Repair histogram plots when doing scatter stuff so you can see densities better relative to 
  36. [ ] sf=sf{1}; should be eliminated IN EVERY SINGLE FILE!
  37. [ ] Grep for TODO's, FIXME's, etc in existing files and add them to this list

* Architectual Improvements
  1. [ ] FIR module should have multiple sets of COEFS so it can do per-file filtering
  2. [ ] NPNL module should have multiple sets of NLs allowed to float on each
  3. [ ] Plot_model() should scan model to look for plotabble fns
	 Call any modules with property plotme_during_summary, do that.
	 If there are multiple functions in plotme_during_summary, print them horizontal to each other
  4. [ ] Modelfiles should include batch# instead of a list of files it was trained on
	 Why: It is unlikely that different batches will share the same modelfile structure
	 Why: Modelfilenames are getting pretty long and cumbersome
	 Why: It puts the batch# information somewhere in the modelfile, which doesn't happen currently.
  5. [ ] Fitters should be able to have their own database-searchable string
	 Some fitters may be really weird
	 I am not a module, yet I want to try to make 'best fitting' things just like anybody else, and save my results	
  6. [ ] Models need associated 'summarize' methods in META
	 Why: Need to extract comparable info despite STACK positional differences in model structure.
	 Why: Need a general interface to plot model summaries for wildly different models
	 Difficulty: Auto-generated models will need some intelligence as to how to generate summarize methods for themselves
  7. [ ] Replace 'model groups' abstraction with a list of arbitrary nested model-perturbing functions and associated keywords
	 Why: In the future, more information should be stored in the META structure:
         META.fitter = ...;  % Fitting tools are not specific to a single module, but are actually more global
	 META.scorer = ...;  % Performance metrics are likewise not really modules
	 Why: It would allow mutation of multiple parts of the stack, simultaneously. 
	 Why: Fitters need to have their own arbitrary string to describe their actions, and this is OUTSIDE of the normal module keyword system
  8. [ ] Make a 2D NPNL heightmap nonlinearity
	 Input X is the exitation
	 Input Y is the inhibition
	 Returns Z, the height of the map
	 Data will probably NOT be scattered uniformly around the map.
  9. [ ] Bayesian Performance Metrics
	 Why: Noise model entropy is a metric of performance. (If best-fit noise distribution has low entropy, we know _more_ about the system) 
	 Why: Likelihood is probably a better metric than MSE since large outliers may not affect it as much?
  10. [ ] DB Bug Catcher which verifies that every model file in /auto/data/code is in the DB, and correct
	  Why: Somebody could easily put the DB and filesystem out of sync.
	  Why: image files could get deleted
	  Why: DB table could get corrupted
	  Why: Also, we need to periodically re-run the analysis/batch_240.m type scripts to make sure they are all generated and current
  11. [ ] Batching should work like this: 
	  1. Batch model scripts can share structure. right now all the batches have pretty much identical scripts!
	  2. When work is enqueued, it goes into the NARF table, which has a 'complete?' flag
	  3. Any number of PCs query the DB, try to get 'incomplete' flagged models. DB is atomic, handles conflicts and negates need for server.
	  4. They compute those models, then return values.
	  5. If desired, a local 'manager' on each PC can watch processes, handle timeouts, etc
	  6. Negates need for SSH credentials everywhere, too.
  12. [ ] Fitters need to be composable
	  1. Fit the FIR coefs with reverse correlation first
	  2. Then fit the FIR coefs with Boosting
	  3. Then fit the NL part with fminlsq
	  4. Then have a loop where you do one boosting step and one lsq step.

* Fitting Routines
  1. Fit combo: revcorr->boost (what we do now)
  2. Fit combo: revcorr->boost->sparsify->boost   (Force sparsity and re-boost)
  3. Fit combo: prior->boost
  4. Fit combo: revcorr->boost_with_increasing_sparsity_penalty
  5. Fit combo: revcorr->boost_with_decreasing_sparsity_penalty
  6. Fit combo: zero->boost 
  7. Fit combo: Fit at 100hz, then use that to init a fit at 200Hz, then again at 400Hz.

* ENQUEUING MANAGER PROGRAM:
  1. Do an SQL query to NarfResults to see what exists
  2. Display models to be trained, already trained
  3. Allow deletions of existing models
  4. Display keyword selectors for models at the top
  5. Display keyword selectors for fitters at the top
  6. Display selectors for which cellids can be trained
  7. Checkbox management so that only certain models can be enqueued

* SAFETY VERIFICATION PROGRAM:
  1. Create a test/ directory with many test functions in it
     Each test function:
     - creates a default XXX{1}
     - Puts a single module on the stack
     - Recomputes XXX(1)
     - Checks output vs predetermined values
     
  2. Check that all modules work independently as expected

* THE GREAT NAME REPLACING PROPOSAL
  1. [ ] XXX -> 
  2. [ ] STACK -> 
  3. [ ] STACK.gh -> GUI
  4. [ ] META -> ModelInfo
  5. [ ] FITTER?
  6. [ ] MODULES
  8. [ ] Make a list of every function used purely for side effects, and rename it with a ! at the end
  9. [ ] "training set" -> "estimation set"
  10. [ ] "test set" -> Verification set
  11. [ ] Name convention of STACK vs stack, XXX vs xxx and the difficulty in understanding which one we are looking at! 
	  Lots of hidden assumptions here which are a problem.

* TECHNICALLY HARDER CHUNKS OF WORK
  1. [ ] Depression model fits for 240, 242
  2. [ ] Inhibition/Excitiation model
  4. [ ] 2D Nonparametric Gaussian Mixture Model:
	 For each point, take K nearest neighbors. 
	 Compute 2D gaussian for that point. 
	 Flatten that 2D gaussian and push into SENL's 1D input
  5. [ ] Log Likelihood Fitter: (Any noise model, not just gaussian)
	 MSE is biased towards gaussian noise models, and for real-life data sets the probability tails are always heavier than a gaussian.
	 Subcomponents:
	 - [ ] inter_spike_intervals computation module
         - [ ] bayesian_likelihood() perf metric module
  6. [ ] ABCD Control Blocks with arbitrary functions (start with 1st and second degree polynomials)
  7. [ ] Use a single wavelet transform in place of downsampling + FIR filter
  8. [ ] Write a crash course guide on using NARF

* DEFERRED
** Stephen's boosting verification
  1. A Shrinking step size is stupid simple. Is there a better way?
  2. Can we retire the analysis/TSP files?
  3. Can I retire the modules/exp_filter? 

* DISCARDED WORK
  1. [ ] Push all existing files into the database
  2. [ ] MODULE INIT: Make a module which has a complex init process
	 1) Creates a spanning filterbank of gammatones
	 2) Trains the FIR filter on that spanning filterbank
	 3) Picks the top N (Usually 1, 2 or 3) filters based on their power
	 4) Crops all other filters
  3. [ ] FIX POTENTIAL SOURCE OF BUGS: Not all files have a META.batch property (for 240 and 242)
  4. [ ] A histogram heat map of model performance for each cell so you can see distribution of model performance (not needed now that I have cumulative dist plotter)
  5. [ ] If empty test set is given for a cellid, what should we do? Hold 1 out cross validation? 
  6. [ ] Fix EM conditioning error and get gmm4 started again (Not sure how to fix!)
  7. [ ] Address question: Does variation in neural fuction in A1 follow a continuum, or are there visible clusters?
  8. [ ] A 2D sparse bayes approach. Make a 2D matrix with constant shape (elliptical, based on local deviation of N nearest points) to make representative gaussians, then flatten to 1D to make basis vectors fed through SB.
  9. [ ] CLEAN: Compare_models needs to sort based on training score if test_score doesn't exist.
  10. [ ] FITTER: Regularized boosting fitter
  11. [ ] FITTER: Automatic Relevancy Determination (ARD) + Automatic Smoothness Determination (ASD)
  12. [ ] FITTER: A stronger shrinkage fitter (Shrink by as much as you want).
  13. [ ] FITTER: Three-step fitter (First FIR, then NL, then both together).
  14. [ ] FITTER: Multi-step sparseness fitters (Fit, sparseify, fit, sparsify, etc). Waste of time
  15. [ ] MODULE: Make a faster IIR filter with asymmetric response properties 
  16. [ ] Make logging work for the GUI by including the log space in narf_modelpane?
  17. [ ] IRRITATION: Why doesn't 'nonlinearity' module default to a sigmoid with reasonable parameters?
  18. [ ] IRRITATION: Why isn't there progress in the GUI when fitting?
  19. [ ] IRRITATION: Why isn't there an 'undo' function?
  20. [ ] IRRITATION: Why can't I edit a module type in the middle of the stack via the GUI?
  21. [ ] Right now, you can only instantiate a single GUI at a time. Could this be avoided and the design made more general?	  
	  To do this, instead of a _global_ STACK and XXX, they would be closed-over by the GUI object.
	  Then, there would need to be a 'update-gui' function which can use those closed over variables.
	  That fn could be called whenever you want to programmatically update it. 	  	  	 
  22. [ ] Make gui plot functions response have two dropdowns to pick out colorbar thresholds for easier visualization?
  23. [ ] Make it so baphy can be run _twice_, so that raw_stim_fs can be two different values (load envelope and wav data simultaneously)
  24. [ ] MODULE: Add a filter that processess phase information from a stimulus, not just the magnitude
  25. [ ] Write a function which swaps out the STACK into the BACKGROUND so you can 'hold' a model as a reference and play around with other settings, and see the results graphically by switching back and forth.
  26. [ ] Try adding informative color to histograms and scatter plots
  27. [ ] Try improving contrast of various intensity plots
  28. [ ] Put a Button on the performance metric that launches an external figure if more plot space is needed.
  29. [ ] Add a GUI button to load_stim_from_baphy to play the stimulus as a sound
  30. [ ] FITTER: Crop N% out fitter:
	    1) quickfits FIR
	    2) then quickfits NL
	    3) measures distance from NL line, marks the N worst points
	    4) Looks them up by original indexes (before the sort and row averaging)
	    5) Inverts nonlinearity numerically to find input
	    6) Deconvolves FIR to find the spike that was bad
	    7) Deletes that bad spike from the data
	    8) Starts again with a shrinkage fitter that fits both together
  31. [ ] Expressing NL smoothness regularizer as a matrix
	    A Tikhonov matrix for regression: 
	    diagonals are variance of each coef.
	    2nd diagonals would add some correlation from one FIR coef to the next (smoothness?).
  32. [ ] Sparsity check:
	   For each model,
              for 1:num coefs
               Prune the least important coef
		plot performance
              Make a plot of the #coefs vs performance
  33. [ ] A check of NL homoskedasticity (How much is the variance changing along the abscissa)	     
  34. [ ] FITTER: SWARM. Hybrid fit routine which takes the top N% of models, scales all FIR powers to be the same, then shrinks them.
  35. [ ] Get a histogram of the error of the NL. (Is it Gaussian or something else?)
  36. [ ] Have a display of the Pareto front (Dominating models with better r^2 or whatever)
  37. [ ] FN: Searches for unattached model and image files and deletes them
