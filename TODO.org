* LEFT OFF THINKING ABOUT THIS
  Today I mostly worked on the data selection pane, and how it is graphed in the raw stimulus/resp window. 
  I think the next stage will be to try to pass the stimulus through the preprocessing filter. 
  That's not so hard, but making it general could be tricky
  So I think the first thing to try will be
  1. Try Loading a struct from an mfile,
  2. Try displaying the contents of a directory and selecting one of the mfiles
  3. Try pushing the loaded struct into a data table 
  4. Try pushing the data table into a struct
  5. Try going back down to an mfile again
  6. Do steps 1-5 with a user-definabel function
  7. Then start doing load_model(preproc, downsamp, modelfn) to initialize the GUI, using the above
  8. mod = load_model(preproc, model, stochasticity); % Load the model form
  9. Load the model parameters (save under cellid+stimfile in a 'saved' dir)
  10. 

* BACKLOG 
  - Move Data selection to the right, and everything else down
  - Renaem 'optimization plots' into 'STochasticity plots', and put histogram stuff and scatter stuff there
  - Add a button to load a set of model params and initaialize the GUI accordingly
  - Downsampling is also part of the model, since it is quite similar to the preprocessing transformation
  - Ad a button to load Bandpass information from the params struct  (Look at exptparams.TrialObject.ReferenceHandle object?)
  - Normalize the PSTH
  - Downsampling should be a GUI-editable operation (We should be able to boxcar it, decimate it, or whatever)
  - Handle NaN's better
  - Use resample during the downsampling step. (which applies the Sinc() function)
  - Modularize the Prefilter setup, which must have
    1. A default parameters object
    2. A function which filters a sound response
    3. A function which returns the 'stationary frequency response'
    4. A pack function
    5. An unpack function
  - Experiment with creating a GUI or doing a batch analysis from the command line

* Modules
  - Automatic covering bands filter, which presents downsampled results of gamma or elliptical notched filters spaced across the domains and completely covering the input space
  - Make a second prefilter (full-coverage gammatone bank)
  - Make a 3rd prefilter (full-coverage elliptic filter bank)
  - Increase the size of the GUI viewports  and clean up the labeling

* Koans to reflect upon
  1. Is it faster to prefilter with many different settings, then fit or correlate to each of them, rather than include it in the optimization loop?

* Notes on Stephen's Brain + Code Dump
  cellxcmaster('por012c-b1',238); % intelligently performs batch analysis 238 on cellid 'por012c-b1'
  After the execution of the above, 'params' contains the details of how the analysis was performed.
  params.resploadparms{1} is a way of getting
  params.respfiles gives a list of the files being used during the analysis
  dbget('sBatch', 238); % Returns details about which experiment is actually being performed
  
* There are three very important functions to look at:
  [cellfiledata, times, ...] = cellfiletimes()      % Note that times contains important info about the training set/test set split, such as the fitting method used?
  xcloadfiles      % Performs analysis on multiple files, queries from the database
  xcloadstimresp   % A cleaner, gentler version of the previous file that is probably what I should base my analysis off of. 
 
* Analysis on paper
  Where should the line be drawn between analysis in the DB, partitionining things for your search within the DB, holding out data, etc?
  How should the code accomodate extra dimensions of training in the future, such as behavioral ones? (Even though we don't think we need it now)
  CellID Dimensions: RespFile(), Stimulus #, repetition #, Value at Time
  Other dimensions: PreFilter #, Central filter #, 

* Issues for Stephen :
  1. Where is 'repetitions' visible? The closest thing I see is the 'Ref_Subsets' field returned in the 'parms' struct by 'dbReadData'

* Possible refactoring
  1. Data ordering is perhaps nonstandard, since we need filter(B,A,X,[],2) instead of filter(B,A,X);
  2. Should PREFILTEREDSTIM be a 3D matrix, or is it more convenient to use as a mixture of cell array and 2H matrices.? 
     STIM [30x400000] (30 tones with 400000 samples in time each)
     RESP [30x400000x3] (3 reps)
     PREFILTEREDSTIM{numoffilters} and under each cell [30x400000]
  3.  Rewrite of dbchooserawfile() because it's so damn useful for selecting a file, but let's make it work for multiple stimulus files
      (Should also display well, site and have selectors for channel, unit, etc
  4. Use squeeze() to remove unneeded dimensions from a matrix.
  5. Try filtfilt to avoid affecting the phase of the response
  6. Why is it 'stimpath' and 'stimfile' but 'path' and 'respfile'. it should be 'resppath'?
  7. Why is loadspikeraster the only thing that cares about the 'options' struct?

* CODE TO REVIEW LATER
  - [X] meska_pca()                              Used for doing the spike sorting, the front end. 
  - [ ] RemoteAnalysis/boost_online.m
  - [ ] Utilities/cacheevpspikes.m
  - [ ] cellDB/dbchooserawfile.m
  - [ ] Config/lbhb/BaphyMainGuiItems.m  has some hard-coded defaults for the GUI
  - [ ] Try messing with creating GUIs for structs using 'structdlg.m'
  - [ ] Consider the data for this: /auto/data/daq/Portabello/por010/por010c08_p_SPN
* LUXURY TODO
  - [ ] Write dbchoosecellfiles()
  - [ ] Make DB loading have adjustable rasterization freqs
  - [ ] Use inter_curve_v3 to interactively make FIR things!
  - [ ] Make the stimulus data drive the windowing of the other visualizations
  - [ ] Try adding color to histograms and scatter plots
  - [ ] try improving contrast of various intensity plots
* Possible problems or hacks to study
  - [ ] Negative effects of discretization on Inter-Spike Intervals histogram estimation (Use known data)
  - [ ] Infer the average rate of spiking from the data, then fit your model against that inferred lambd without doing EM all the time.
* HIGH LEVEL TODO:
   1) [ ] Logging and recording multiple models and their performance
   3) [ ] Plots the STRF of the best-fitting model?
   4) [ ] Analyze:  'dai020a-c2', 'mag009b-b1', 'dai008a-c1', 'mag007d-d1' 
   5) [ ] Rank model fits and plot correlations
   6) [ ] Replicate Stephen's results with exitation/inhibition
* ModelFit GUI Design Brainstorm
* -----------------
* Data Selection
  CellID
  Training set(s) 
  Test set(s)
  button to 
  textbox: cellID#
  dropbox: channel
  dropbox: trial class of associated data (and # of responses?)
  textbox: report of relevant data about the data?
  textbox: stimulus frequency
  textbox: response bin size (set to 0 for continuous timings?)
  graph: Rendering of the sound
  dropbox: toggle between rendering of the sound with spectrogram or time
* Preprocessing
   dropbox: filter class
   graph: filter output
   dropbox: graph view in time, graph white noise filtered by this, or as a heat map?
   button: refresh graph
*** Envelope
    textbox: raster frequency
*** Single Gammatone
    textbox: center freq
    textbox: bandwidth
*** Gammatone filter bank
    textbox: min freq
    textbox: max freq
    textbox: num filters (or maybe, vector of filter center freqs, so I could pick just the few that are important?)
    checkbox: align phase
* Model Class
  dropbox: model
  pane with checkboxes (editable or not) and editboxes: model params       (Hidden: will need on-the-fly generated functions which map structs to vectors and back)
* Performance
** TODO: Add BIC or AIC to the model-comparison part of my figure
* Ask stephen
  [ ] Split Keyboard?
