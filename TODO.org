* Questions, and Graphs that Answer Them:
  1. What qualitatively influences FIR coefficients that we don't want to think about right now?
     - [ ] Given constant everything (no NL), what is the effect of compressor on FIR coefs?
     - [ ] Given constant everything (const compressor), what is the effect of a NL on performance?
     - [ ] Given constant everything (log2, no NL), what is the effect of a fitter on coefs?
     - [ ] Given constant everything (log2, with NL), what is the effect of a fitter on coefs?
  2. Would adding a log compressor as an EXTRA channel rather than a replacing channel be useful, so that the exact compression could be found as a balance between the two?
  3. Would normalizing the output of the FIR be useful for allowing the FIR to be fit (when comparing active/passive)
     (It would let me automatically know sigmoidal mean, although I don't know if that would really help with the fits very much.)
  4. Does it make sense to use a linear filter on a positive definite input? Should there be a threshold after the FIR?
  5. Are neurons clusterable according to which models fit them best?
   
* NEW FEATURES
  1. [ ] N-step fitter (train FIR in common, train NL across each separately)
	 Surprisingly difficult to make several models need to be fit all on the same data. yet ALSO need to run on different behavioral states. 
	 WHY:
         1. Violates my implicit expectation of 1 fitter -> 1 model. Now I have 1 fitter-> many models.
	 2. Now that training_set{} may be edited, it shouldn't really be copied from one XXX{1} to XXX{2} and so on.
	 Solution ideas: 
	 - Quick hack: five new fitters added
	   NL1, trains on all, but only trains NL on 1st
	   NL2, trains FIR on all, but only trains NL on 2nd, 
	   etc
	 - Quick hack: Store each of the five models param sets in the same model
	 - 
	 

  2. [ ] Generalize N-step fitter to let a particular module or set of modules float. 
	 ?????
  3. [ ] PERF METRIC: inter_spike_intervals + bayesian_likelihood()
  4. [ ] I think normalizing the FIR filter coefs BEFORE doing the mean across jackknifes would really help. 
	 Probably output nonlinearities need to be refit after any averaging, as well.
  5. [ ] FN: Plot multiple models' NPNLs on the SAME PLOT?
  6. [ ] FN: Cleanliness of a FIR filter based on weight of DC coef, and how 'peaky' it is. Set highest peak to zero, then compare overall magnitude to before. This gives a series of moments.
  7. [ ] FN: 'set_module_field' (finds module, sets field, so you can mess with things later in scripts)
  8. [ ] MODULE: Make a faster IIR filter with asymmetric response properties 
  9. [ ] FITTER: SWARM. Hybrid fit routine which takes the top N% of models, scales all FIR powers to be the same, then shrinks them.
  10. [ ] MODULE: Make Concat Second Order Terms work for any higher order nchoosek type stuff
  11. [ ] MODULE: Standardized single/multi channel gammatone filter
  12. [ ] MODULE: Standardized single/multi channel elliptic filter 
  13. [ ] MODULE FN: Provide functions to cover the input space logarithmically with filters
  14. [ ] MODULE INIT: Make a module which has a complex init process
	  1) Creates a spanning filterbank of gammatones
	  2) Trains the FIR filter on that spanning filterbank
	  3) Picks the top N (Usually 1, 2 or 3) filters based on their power
	  4) Crops all other filters
  15. [ ] MODULE FN: Provide an auto-init for the filters which cover the input space, train filters on that, and picks the channel with the most power. It does this once wide, then once narrow.
  16. [ ] MODULE: Add a module which can pick out a particular dimension from a vector and give it a name as a signal
  17. [ ] REFACTOR: Replace all the 'true' and 'false' arguments with textual flags and varargin that are more descriptive
  18. [ ] REFACTOR: the Fitters because they are all pretty much the same damn thing over and over again
  19. [ ] MODULE: Build a non-cheating model which extracts envelopes directly from the WAV files using an elliptic or gammatone prefilter
  20. [ ] FN: Cleaning function which DELETES any models which have NaNs for test/train fits
  21. [ ] FITTER: Import fitting routines from STRFlab
  22. [ ] Roll model summary caches and select_summaries into Stephen's BAPHY, since in the end all I did was reinvent yet another crappy RDBMS

* END USER CONVENIENCES
  1. [ ] Why isn't auto recalc the default?
  2. [ ] Make logging work for the GUI by including the log space in narf_modelpane?
  3. [ ] IRRITATION: Why doesn't 'nonlinearity' module default to a sigmoid with reasonable parameters?
  4. [ ] IRRITATION: Why doesn't it show the model save filename so I can see which file I just loaded if I forgot?
  5. [ ] IRRITATION: Why doesn't every plotted signal have a legend?
  6. [ ] IRRITATION: Why don't the X (or at least the Y) axes have scales?
  7. [ ] IRRITATION: Why isn't there an 'undo' function?
  8. [ ] IRRITATION: Why can't I resize windows?
  9. [ ] IRRITATION: Why isn't there progress in the GUI when fitting?
  10. [ ] IRRITATION: Why are the editable text boxes so damn small?
  11. [ ] IRRITATION: Why can't I edit a module type in the middle of the stack via the GUI?
  12. [ ] Write a crash course guide on using NARF
  13. [ ] Remember to invalidate data BELOW the present point on a table-edit callback... and to update the gui to reflect this!

* BUG FIXES AND CLEANING
  1) [X] Paths have become a bit messy: grep for NARF_PATH and correct (also: replace with filesep when possible)
  2) [X] Cleaner way of building models in a script than accessing by index number?
  3) [X] Look for obvious repetition and make some more functions in util/
  4) [ ] Many repeated blocks of code have evolved and need to be destroyed.
  5) [ ] Names probably could use some rethinking as well, especially defaults (like using 'stim' default even in the fitting algorithms, for example)
  6) [ ] Add error handling (catch/throw) around EVERY CALL to a user defined function
  7) [ ] In retrospect, 'gui' and 'plot_gui' stuff probably shouldn't be stored in the XXX or STACK structures...should it be in a 3rd structure?
  8) [ ] Ensure that no closures of data are being done by methods. Methods should accept the module object as their first argument, not close over anything.
  9) [ ] It's not quite right to have the 'replot' command be part of the the 'plot_popup fn callback'. Needs to be re-thought.
  10) [ ] Go through the TODO's, FIXME's, etc in existing files
  11) [ ] Create a module methods directory for shared methods
  12) [ ] Create a module keywords directory for helping with combinatoric name management.
  13) [ ] make anything named 'do_' into a method for use with modules?
  14) [ ] make anything named 'update_' into a function used purely for its side effects?
  15) [ ] Delete the GUI objects whenever you 'apply' since they may need to be recreated?

* DESIGN QUESTIONS TO BRAINSTORM:
  1. [X] How can sane initial conditions for optimization be automatically arrived at without extra script-writing?
	 Auto-initialization of model params is done by allowing modules to update their design based on the data by calling the optional 'auto_init' method.
	 Arg 1 is the STACK, not including the model itself. 
	 Arg 2 is the XXX data input, not including the model's output data itself. 
  2. [X] How can jack-knifing be integrated in to the optimization routine to prevent over-fitting?
	 Split the big long RESP and STIM vectors in fit_with_lsqcurvefit into 10 chunks
	 Take groups of 9 of those chunks, run lsqcurvefit, then test on remaining chunk
	 Take weighted average of all jackknifed solutions, weighting each by inverse variance? Or just mean, if we assume they all have same variance?
	 Return weighted average.
  3. [X] How should optimization constraints be incorporated in the design?
	 Probably the easiest way is to define a structure which may be used by pack/unpack to create upper and lower bounds, which are then passed to the optimization routine
	 opt_hints = struct('alpha', [-1 3], 'beta', [0 inf]); % Constrain alpha from -1 to 3 and beta from 0 to infinity. 
  4. [X] How should models be automatically generated in a quick and scriptable way?
	 See analysis/test_likely_candidates.m
  5. [X] How can design internal degrees of freedom be detected and corrected during optimization?
	 (Probably they cannot!)
  6. [X] There needs to be a place to store information about a whole model. 
	 For example, 'model name' and 'fitter' are two examples of fields that don't really belong in a module.
  7. [X] There is no best fitting routine, only fitting routines which work better for different cells. Allow them all a chance to run by making them module parameters.
  8. [X] Can jackknifing or the equivalent be applied to ANY fitting routine as a higher level function
	 If we only have one data file, how can we hold out some fraction of the stimuli so that we can do training/test on a single data file?
	 Solution:
	 - Fit routines use a 'score'
	 - The stack gives the score
	 - The score needs to be calculated from a jackknife
	 - How can data be jackknifed without modifying the stack?
	 - Immediately after the loading, zero a chunk of the stim and respavg (save the original, of course)
	 - Do a fit with whatever routine you want
  9. [ ] Right now, it's very convenient to be able to have the 'fitter' and 'score' quantity to be in modules
	 I can plug in all the module groups and let the fitter run. I can compare different fit routines automatically.
	 However, a fitter is not really part of a module, it's part of a whole model.
	 Therefore, in the future, the fitter and score quantity should be stored in the model META structure.
	 On the other hand, I need to justify this: Why should this be done instead of leaving it in the STACK? What we have right now works and is convenient.
	 (Because we may want to try multiple fit routines, and pick the model with the best training score?)
	 (Because I expect that model specific fitters are necessary? That isn't a reason!)
  10. [ ] Right now, you can only instantiate a single GUI at a time. Could this be avoided and the design made more general?	  
	  To do this, instead of a _global_ STACK and XXX, they would be closed-over by the GUI object.
	  Then, there would need to be a 'update-gui' function which can use those closed over variables.
	  That fn could be called whenever you want to programmatically update it. 	  	  	 
  11. [ ] It is awkward in non-parametric non-linearity module to recalc the phi every time you need it for graphing. Some place to cache it would be good without risking cache staleness.

* LUXURY, UNESSENTIAL TODO ITEMS 
  - [ ] Make it so baphy can be run _twice_, so that raw_stim_fs can be two different values (load envelope and wav data simultaneously)
  - [ ] Make gui plot functions response have two dropdowns to pick out colorbar thresholds for easier visualization?
  - [ ] MODULE: Add a filter that processess phase information from a stimulus, not just the magnitude
  - [ ] Write a function which swaps out the STACK into the BACKGROUND so you can 'hold' a model as a reference and play around with other settings, and see the results graphically by switching back and forth.
  - [ ] Write dbchoosecellfiles() and connect it to NARF_MODELPANE
  - [ ] Try adding informative color to histograms and scatter plots
  - [ ] Try improving contrast of various intensity plots
  - [ ] Put a Button on the performance metric that launches an external figure if more plot space is needed.
  - [ ] Add a GUI button to load_stim_from_baphy to play the stimulus as a sound
  - [ ] FITTER: Crop N% out fitter:
	  1) quickfits FIR
	  2) then quickfits NL, 
	  3) measures distance from NL line, marks the N worst points
	  4) Looks them up by original indexes (before the sort and row averaging)
	  5) Inverts nonlinearity numerically to find input
	  6) Deconvolves FIR to find the spike that was bad
	  7) Deletes that bad spike from the data
	  8) Starts again with a shrinkage fitter that fits both together

