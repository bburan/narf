* Stephen's clever Narf Hack:
  - Not the most composable solution, but it's quick and solves the problem!
  - New Keyword that manually does the fits then combines them
    save the xxx
    for every stimfile in the training set
       reset xxx(1) to just have that one stimfile
       fit using boost
       save the STACK params somewhere
    endfor
    Once you are done, groupe those saved STACK params as paramset
    Adjust a splitter and unifier as appropriate
    Now the model should recalc just fine and give a single fit
    However, it won't be re-fittable 

* IMPROVED QUEUE MANAGER PROGRAM
** Data Structures
   - NarfResults
     | Field      | Type             | Null | Key | Default           | Extra                       | Notes                             |
     |------------+------------------+------+-----+-------------------+-----------------------------+-----------------------------------|
     | id         | int(10) unsigned | NO   | PRI | NULL              | auto_increment              |                                   |
     | cellid     | varchar(255)     | YES  | MUL | NULL              |                             |                                   |
     | batch      | int(11)          | YES  | MUL | NULL              |                             |                                   |
     | modelname  | text             | YES  | MUL | NULL              |                             |                                   |
     | r_test     | double           | YES  |     | NULL              |                             |                                   |
     | r_fit      | double           | YES  |     | NULL              |                             |                                   |
     | score      | double           | YES  |     | NULL              |                             |                                   |
     | sparsity   | double           | YES  |     | NULL              |                             |                                   |
     | modelpath  | text             | YES  |     | NULL              |                             |                                   |
     | modelfile  | text             | YES  |     | NULL              |                             |                                   |
     | figurefile | text             | YES  |     | NULL              |                             |                                   |
     | githash    | varchar(255)     | YES  |     | NULL              |                             |                                   |
     | lastmod    | timestamp        | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP | When was the model last modified? |
     
     Add these:
     | Field           | Type      | Null | Key | Default | Extra | Notes                                                                            |
     |-----------------+-----------+------+-----+---------+-------+----------------------------------------------------------------------------------|
     | respfiles       | text      |      |     |         |       | contents of XXX0                                                                 |
     | lastVerified    | timestamp | YES  | ?   | ?       | ?     | When was the model/image/etc last checked for DB consistency?                    |
     | lastFit         | timestamp |      |     |         |       | When was the model last fit                                                      |
     | isHidden        | char(1)   | NO   |     |         |       | T or F                                                                           |
     | isDeleted       | char(1)   | NO   |     |         |       | T or F                                                                           |
     | estset          |           |      |     |         |       |                                                                                  |
     | valset          |           |      |     |         |       |                                                                                  |
     | est_l1          |           |      |     |         |       |                                                                                  |
     | est_mse         |           |      |     |         |       |                                                                                  |
     | est_corr        |           |      |     |         |       |                                                                                  |
     | est_likelihood  |           |      |     |         |       |                                                                                  |
     | est_aposteriori |           |      |     |         |       |                                                                                  |
     | est_bic         |           |      |     |         |       |                                                                                  |
     | jobStatus       |           |      |     |         |       | When created, set to 0. Shows Job system status so double-queuing doesn't occur. |
     | sparsity        | text      |      |     |         |       |                                                                                  |
     | smoothness      | text      |      |     |         |       |                                                                                  |

   - NarfQuestions: For scientific queries
     | Field         | Type      | Null | Key | Default | Extra | Notes                                                |
     |---------------+-----------+------+-----+---------+-------+------------------------------------------------------|
     | question      | text      |      |     |         |       | The question we asked.                               |
     | answer        | text      |      |     |         |       | Our current answer.                                  |
     | modeltree     | text      |      |     |         |       | A model keyword tree; all branches are compared      |
     | batch         | int(11)   |      |     |         |       | Associated with a particular batch                   |
     | XXX0          | text      |      |     |         |       | cellid, est_set, val_set, filecodes                  |
     | summaryfigure | text      |      |     |         |       | Summarizes the answer to the question                |
     | isAnswered    | char(1)   |      |     |         |       | When you have decided you have answered the question |
     | lastmod       | timestamp |      |     |         |       |                                                      |
     | datapartiton  | char(255) |      |     |         |       | all, perfile, perfilecode                            |

   - NarfBatches
     | batchname     | varchar(255) |   |   |   |   | More generic names                                   |
     | cellid        | varchar(255) |   |   |   |   |                                                      |
     | est_set       | text         |   |   |   |   |                                                      |
     | val_set       | text         |   |   |   |   |                                                      |
     | tags          | text         |   |   |   |   |                                                      |
     | lastmod       | timestamp    |   |   |   |   |                                                      |
 
* Easy stuff for today
  1. [ ] The same method for flattening in "NORMALIZE" should also be used for flattening in "scatter plots". Grep through and remove any 'bullshit concats'
	       V1 = [];   V2 = [];    for ii = 1:length(x.training_set),        sf = x.training_set{ii};       V1 = cat(1, V1, x.dat.(sf).(mdl.input1)(:));        V2 = cat(1, V2, x.dat.(sf).(mdl.input2)(:));    end    R = corrcoef(excise([V1 V2]));
  2. [ ] Fix write permissions for images, models
  3. [ ] COMPARE Models Functions
	 A function that takes N filenames
	 It loads them up, checks that they have identical model structure
	 Then it extracts any parameters that differ. 
  4. [ ] Loadstimfrombaphy should haev a "chop_beginning" parameter that removes the first N samples
  5. [ ] Clean up saved_analysis, saved_models, saved_images

	 
* Actions
  1. [ ] A better queuing script
	 - [ ] Sorts according to QUESTIONS 
	 - [ ] Scatter plot comparison functionality
	 - [ ] Overwrite existing models?
	 - [ ] Resume dead models?
	 - [ ] Force git sync?
	 - [ ] Force git clean?
	 - [ ] Check for:
	       - [ ] dead/jobs
	       - [ ] DB contents and Filesystem still sync up
	       - [ ] Everything is enqueued
  2. [ ] Tool to start comparing models:
	 - [ ] Specify models with a function
	 - [ ] It tells you how many matching models were found, and how many were expected
	 - [ ] Ability to extract parameters from every model
	 - [ ] Calls your special analysis function
	 - [ ] Hold out data 	 
  3. [ ] Repair Narf Browser
	 - [ ] Sparsity is not going into the DB
	 - [ ] More metrics should go into the DB
	 - [ ] Elitist browsing (Shows ONLY THE HIGHEST MODEL of each cell given current masks)
	 - [ ] Comparison finders (Allows you to select two model structures for comparisons)
	 - [ ] Antialiasing problem when saving images
	 - [ ] Heat Map current display button in NARF
	 - [ ] AND/OR/NOT query token filter, or 'In position 3' filter
	 - [ ] Generic 'modelstring' query space
	 - [ ] Arbitrary keyword substring stuff
         - [ ] The total number of spikes in each behavior respfile should be displayed?
  4. [ ] Default per-paramset, per-channel heatmap graph fns:
	 - [ ] Loadstimfrompbaphy
	 - [ ] Nonrmalize channels
	 - [ ] FIR filter
	 - [ ] Nonlinearity
  8. [ ] Repair Fitters 
         - [ ] Remove, then re-add test_set data by default to make fitters faster
         - [ ] How will LSQ and sparsebayes modules work with a generic META.performance_metric() function?
  9. [ ] Add new functionality to the do_scatter_plot method
	 - [ ] Instead of plotting a scatter plot as points, use a fine-grid HEAT MAP
	       Use grayish/blackish 
  10. [ ] Profile the time spent during boosting and look for optimizations:
          - Is there a way to speed up NPNL? Unique is DOG SLOW because it sorts.
          - Write a FIR speed booster, which uses N vectors (one per FIR coef, which re a product with the stimulus). Each boost step, only 1 coef need be updated.
          - Aha! If I wrote a FASTFILTER closed-over function, and provided it with a way to update its closed-over vector in response to a boost step, I could use the same code for both fast FIR filtering and NPFNL? No, wait, that wouldn't work...the stimulus changes EVERY single time.
  11. [ ] Possible features to extract (And what what is needed to detect them)
          - Spatial location of source (Phase difference or  )
          - Freq (STRF)
          - Freq direction rising/falling (STRF with diagonal band)
          - Pitch (STRF with harmonics)
          - Timbre (STRF with harmonics)
          - Vowels, Consonants 
          - Onsets, offturns (STRF)
  12. [ ] What if we use RESPAVG to compute the depression state, and fit the depression amounts?
  13. [ ] NPNL with autocorrelation of last few ms
  14. [ ] What are the covariances of the FIR coefs? (RCORR)
  15. [ ] Instead of getting the full covariance matrix, just get per-parameter variances.
	  Vary each parameter deterministically or stochastically
	  Estimate the amount variance which decreases the MSE by a set amount
	  This should let us determine the "relevancy" of each parameter
	  Sort all the parameters, and take just the most relevant ones!

* FIXME: Irregularities
  - Not all nonlinearities can accomodate NaNs in their code?
  - I think NPNL (or Normalize channels) is having a freak out when the FIR coefs are zero. 
  - fit_sparsebayes.m, fit_lsq.m, and fit_lsqnonlin.m do not respect META.performance_metric()
  - Jackknifing doesn't work with performance metrics besides MSE right now?

* FIXME: Unresolved Problems
** Can fitters understand how to work on each paramset separately?
   I wish they could. Right now, there is a subtle problem when we use a splitter on the FIR filter:
   - Boosting slows down 5x. We have 5x24 = 120 parameters per boost step. 
   - Fitting in one split regime is subtely interacting with fitting in another. Early stopping worsens this effect.

* LOW PRIORITY CLEANUP
  1. [ ] Grep for TODO's, FIXME's, etc in existing files and add them to this list
  2. [ ] Plot a SINGLE paramset's SINGLE high-bandwidth channel as a spectrogram
  3. [ ] Replace all the 'true' and 'false' arguments with textual flags and varargin that are more descriptive
  4. [ ] It's not quite right to have the 'replot' command be part of the the 'plot_popup fn callback'. Needs to be re-thought
  5. [ ] Can functions in the keywords directory be set so the 'current folder path' is NOT accidentally giving access to other keyword directory functions?
  6. [ ] Add error handling (catch/throw) around EVERY CALL to a user defined function, trigger popup?
  7. [ ] MODULE: Build a non-cheating model which extracts envelopes directly from the WAV files using an elliptic or gammatone prefilter
  8. [ ] MODULE: Add a module which can pick out a particular dimension from a vector and give it a name as a signal
  10. [ ] MODULE: Standardized single/multi channel gammatone filter
  11. [ ] MODULE: Standardized single/multi channel elliptic filter 
  12. [ ] FN: Cover an input space logarithmically with filters

* THE GREAT NAME REPLACING PROPOSAL
  1. [ ] WHATEVER IS GOING INTO XXX{1} should be given to fit_single_model as well! When I'm not using BAPHY it should still be able to work.
  2. [ ] "training set" -> "estimation set"
  3. [ ] "test set" -> "Validation set"
  4. [ ] META -> (Suggestion: Should this be MODELINFO, instead of just 'metadata'?)
  5. [ ] STACK -> (Suggestion: Should this be MODULES, MDLS, etc?)
  6. [ ] MODULES (What would this become? )
  7. [ ] NarfResults -> NarfModels
  8. [ ] XXX -> ??
  9. [ ] FITTER (containing a list of available fitters?)
  10. [ ] Make a list of every function used purely for side effects, and rename it with a ! at the end
  11. [ ] Name convention of STACK vs stack, XXX vs xxx and the difficulty in understanding which one we are looking at! 
	  Lots of hidden assumptions here which are a problem. Plot modules have access to AFTER data, too.

* TECHNICALLY HARDER CHUNKS OF WORK
  1. [ ] Inhibition/Excitiation model
  2. [ ] Log Likelihood Fitter: (Any noise model, not just gaussian)
	 Why: Noise model entropy is a metric of performance. (If best-fit noise distribution has low entropy, we know _more_ about the system) 
	 Why: Likelihood is probably a better metric than MSE since large outliers may not affect it as much?
	 MSE is biased towards gaussian noise models, and for real-life data sets the probability tails are always heavier than a gaussian.
	 Subcomponents:
	 - [ ] inter_spike_intervals computation module
         - [ ] bayesian_likelihood() perf metric module
  3. [ ] GMM without slow EM step:
	 For each point, take K nearest neighbors. 
	 Compute 2D gaussian for that point. 
	 Flatten that 2D gaussian and push into SENL's 1D input
  4. [ ] ABCD Control Blocks with arbitrary functions (start with 1st and second degree polynomials)
  5. [ ] Use a single wavelet transform in place of downsampling + FIR filter
  6. [ ] Write a crash course guide on using NARF
  7. [ ] http://www.mathworks.com/matlabcentral/fileexchange/27662-evolve-top-and-bottom-envelopes-for-time-signals-i-e

* DISCARDED/ABANDONED IDEAS
  1. [ ] FN: 'set_module_field' (finds module, sets field, so you can mess with things more easily in scripts)
  2. [ ] Push all existing files into the database
  3. [ ] MODULE INIT: Make a module which has a complex init process
	 1) Creates a spanning filterbank of gammatones
	 2) Trains the FIR filter on that spanning filterbank
	 3) Picks the top N (Usually 1, 2 or 3) filters based on their power
	 4) Crops all other filters
  4. [ ] FIX POTENTIAL SOURCE OF BUGS: Not all files have a META.batch property (for 240 and 242)
  5. [ ] A histogram heat map of model performance for each cell so you can see distribution of model performance (not needed now that I have cumulative dist plotter)
  6. [ ] If empty test set is given for a cellid, what should we do? Hold 1 out cross validation? 
  7. [ ] Fix EM conditioning error and get gmm4 started again (Not sure how to fix!)
  8. [ ] Address question: Does variation in neural fuction in A1 follow a continuum, or are there visible clusters?
  9. [ ] A 2D sparse bayes approach. Make a 2D matrix with constant shape (elliptical, based on local deviation of N nearest points) to make representative gaussians, then flatten to 1D to make basis vectors fed through SB.
  10. [ ] CLEAN: Compare_models needs to sort based on training score if test_score doesn't exist.
  11. [ ] FITTER: Regularized boosting fitter
  12. [ ] FITTER: Automatic Relevancy Determination (ARD) + Automatic Smoothness Determination (ASD)
  13. [ ] FITTER: A stronger shrinkage fitter (Shrink by as much as you want).
  14. [ ] FITTER: Three-step fitter (First FIR, then NL, then both together).
  15. [ ] FITTER: Multi-step sparseness fitters (Fit, sparseify, fit, sparsify, etc). Waste of time
  16. [ ] MODULE: Make a faster IIR filter with asymmetric response properties 
  17. [ ] Make logging work for the GUI by including the log space in narf_modelpane?
  18. [ ] IRRITATION: Why doesn't 'nonlinearity' module default to a sigmoid with reasonable parameters?
  19. [ ] IRRITATION: Why isn't there progress in the GUI when fitting?
  20. [ ] IRRITATION: Why isn't there an 'undo' function?
  21. [ ] IRRITATION: Why can't I edit a module type in the middle of the stack via the GUI?
  22. [ ] Right now, you can only instantiate a single GUI at a time. Could this be avoided and the design made more general?	  
	  To do this, instead of a _global_ STACK and XXX, they would be closed-over by the GUI object.
	  Then, there would need to be a 'update-gui' function which can use those closed over variables.
	  That fn could be called whenever you want to programmatically update it. 	  	  	 
  23. [ ] Make gui plot functions response have two dropdowns to pick out colorbar thresholds for easier visualization?
  24. [ ] Make it so baphy can be run _twice_, so that raw_stim_fs can be two different values (load envelope and wav data simultaneously)
  25. [ ] MODULE: Add a filter that processess phase information from a stimulus, not just the magnitude
  26. [ ] Write a function which swaps out the STACK into the BACKGROUND so you can 'hold' a model as a reference and play around with other settings, and see the results graphically by switching back and forth.
  27. [ ] Try adding informative color to histograms and scatter plots
  28. [ ] Try improving contrast of various intensity plots
  29. [ ] Put a Button on the performance metric that launches an external figure if more plot space is needed.
  30. [ ] Add a GUI button to load_stim_from_baphy to play the stimulus as a sound
  31. [ ] FITTER: Crop N% out fitter:
	    1) quickfits FIR
	    2) then quickfits NL
	    3) measures distance from NL line, marks the N worst points
	    4) Looks them up by original indexes (before the sort and row averaging)
	    5) Inverts nonlinearity numerically to find input
	    6) Deconvolves FIR to find the spike that was bad
	    7) Deletes that bad spike from the data
	    8) Starts again with a shrinkage fitter that fits both together
  32. [ ] Expressing NL smoothness regularizer as a matrix
	    A Tikhonov matrix for regression: 
	    diagonals are variance of each coef.
	    2nd diagonals would add some correlation from one FIR coef to the next (smoothness?).
  33. [ ] Sparsity check:
	   For each model,
              for 1:num coefs
               Prune the least important coef
		plot performance
              Make a plot of the #coefs vs performance
  34. [ ] A check of NL homoskedasticity (How much is the variance changing along the abscissa)	     
  35. [ ] FITTER: SWARM. Hybrid fit routine which takes the top N% of models, scales all FIR powers to be the same, then shrinks them.
  36. [ ] Get a histogram of the error of the NL. (Is it Gaussian or something else?)
  37. [ ] Have a display of the Pareto front (Dominating models with better r^2 or whatever)
  38. [ ] FN: Searches for unattached model and image files and deletes them
  39. [ ] Models need associated 'summarize' methods in META
	  Why: Need to extract comparable info despite STACK positional differences in model structure.
	  Why: Need a general interface to plot model summaries for wildly different models
	  Difficulty: Auto-generated models will need some intelligence as to how to generate summarize methods for themselves
  40. [ ] DB Bug Catcher which verifies that every model file in /auto/data/code is in the DB, and correct
	  Why: Somebody could easily put the DB and filesystem out of sync.
	  Why: image files could get deleted
	  Why: DB table could get corrupted
	  Why: Also, we need to periodically re-run the analysis/batch_240.m type scripts to make sure they are all generated and current
  41. [ ] Put a line in fit_single_model that pulls the latest GIT code before fitting?
  42. Fit combo: revcorr->boost (what we do now)
  43. Fit combo: revcorr->boost->sparsify->boost   (Force sparsity and re-boost)
  44. Fit combo: prior->boost
  45. Fit combo: revcorr->boost_with_increasing_sparsity_penalty
  46. Fit combo: revcorr->boost_with_decreasing_sparsity_penalty
  47. Fit combo: zero->boost 
  48. Fit combo: Fit at 100hz, then use that to init a fit at 200Hz, then again at 400Hz.
  49. Replace my nargin checks with "if ~exist('BLAH','var'),"
  50. sf=sf{1}; should be eliminated IN EVERY SINGLE FILE! 
  51. [ ] FIR filter needs an 'ACTIVE FIR COEFS' plot which only displays paramsets matching selected
  52. [ ] IRRITATION: Why can't I resize windows?
  53. Stephen will do the init condition for FIRN coefs split into two filters of positive/negative coefs only    
  54. Write a termination condition that ends when "delta = 10^-5 * max-delta-found-so-far" for boosting
  55. Why an FPGA would kick ass for this stuff(You could try all 300 coefficient boosting steps simultaneously, this is an embarassingly parallel problem)
** Crazyboost
   How's this for a fitter?
   Boosting works well, and tries every possible step before taking a new one.
   That's good and deterministic, but maybe we could speed things up by randomly sorting the steps (so as not to be biased towards early values)
   Then just take a step _any_ time it improves the score
   It would take many more steps each iteration.
   No guarantee it would converge, but maybe we could do it just to get started more quickly
** Can Jackknifes be stored in the same model file?
  No, this should not be done.   

** Stephen's boosting verification
  1. A Shrinking step size is stupid simple. Is there a better way?
  2. Can we retire the analysis/TSP files?
  3. Can I retire the modules/exp_filter? 

** SAFETY VERIFICATION PROGRAM:
  1. Create a test/ directory with many test functions in it
     Each test function:
     - creates a default XXX{1}
     - Puts a single module on the stack
     - Recomputes XXX(1)
     - Checks output vs predetermined values
  2. Check that all modules work independently as expected
  3. Checks that DB and modelfiles still sync up
** Rewrite JOBS system
    + Put a "Complete?" 
    + Any number of PCs query the DB, try to get 'incomplete' flagged models. DB is atomic, handles conflicts and negates need for server.
    + They compute those models, then return values.
    + If desired, a local 'manager' on each PC can watch processes, handle timeouts, etc
    + Negates need for SSH credentials everywhere, too.
** Improve BAPHY Interface
   - Right now BAPHY has a complicated interface for a simple thing:
     - All we really want is the stimulus and response(s)
     - Selecting data ourselves, jackknifing it, hacking it out, etc are messy since half of it is done in Baphy and half in NARF
