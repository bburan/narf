* MILESTONE
  Fit using TORC data to produce an STRF, show to Stephen and make him happy. (Bonus fun: If you can get one STRF for inhibition, one for excitation, that would be neat.)
    
* Cleaning/Refactoring
  - Avoid cla's in user-space functions
  - Provide a more concise way of finding user-space guis in the call tree above
  - Add a few useful functions to generic_methods
  - Replace all the 'length' and 'size' things with 'numel' where appropriate
  - Automatically try to load Bandpass information from the arg_params struct passed to the bandpass filter fn (Look at exptparams.TrialObject.ReferenceHandle object?)
  - Go through the TODO's in my files and do a triage

* Next steps:
  - Add a button or textbox to "load analysis" settings that have already been found, so that saved data from a batch can be quickly browsed.
  - Write a generic pack/unpack function to expose parameters to the optimization
  - Add a button to "save analysis", connecting the stimfile train/test sets, model structure and params, optimization method, and GIT code hash number all together in a single, savable structure.
  - Add error handling (catch/throw) around EVERY CALL to a user defined function
  - Normalize the binning as a rate in the very first step
  - Handle NaN's better...right now they cause problems!

* How could functions be passed from one to the next?
  All functions are assumed to accept TWO arguments and return TWO arguments
  Those arguments are the STACK data structure and the X data structure

* When called with no arguments, each function returns 2 arguments:
  1. The 'meta' information about the function
  2. The 'params' struct, which specificies the default parameters

* What is narf_modelpane used for?
  It was written:
  1. To visualize a model's behavior on data
  2. To edit a model easily and explicitly
  3. To encapsulate all assumptions about the model in a stack
  4. To select which parameters are to be optimized with an optimization routine. 
     (The optimization routine GETS a copy of the stack, plays around with the data, then SETS the stack again after optimization is complete.)

* STACK data structure
  A cell array, with the present params struct being first, containing the functions and their parameters that were applied to reach this point. 
  |-------------------------+---------------------------------------------------------------------------------------|
  | STACK{}.name            | Function file name                                                                    |
  | STACK{}.fn              | The function handle                                                                   |
  | STACK{}.pretty_name     | User readable pretty function name                                                    |
  | STACK{}.plot_fns        | Struct array with fields (pretty_name, fn)                                            |
  | STACK{}.editable_fields | Fields that may be user edited                                                        |
  | STACK{}.isready_pred    | A predicate function that is passed (STACK, X) and returns true iff it's ready to run |
  | STACK{}.gh              | "Gui Handles" structure.                                                              |
  |-------------------------+---------------------------------------------------------------------------------------|

* X data structure
  A cell array, with the most recent data being first. The contents of each cell could be anything. For my cases a struct seems to be most convenient.
  |----------------------------+--------------------------------------------------------------+---------+------------------------------|
  | SYMBOL                     | DESCRIPTION                                                  | TYPE    | SET OR MODIFIABLE BY         |
  |----------------------------+--------------------------------------------------------------+---------+------------------------------|
  | X{}.dat.().cellid          | Name of the cellid                                           | String  | -                            |
  | X{}.dat.().stimfile        | Name of the stimfile                                         | String  | -                            |
  | X{}.dat.().include_prestim | Boolean. 1 prestim was included, 0 otherwise                 | Boolean | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_stim_fs     | Raw stimulus frequency                                       | Double  | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_resp_fs     | Raw response frequency                                       | Double  | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_stim        | Raw stimulus                                                 | [SxN]   | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_resp        | Raw spike timings                                            | [SxMxR] | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_stim_time   | Time vector for stimulus                                     | [1xN]   | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_resp_time   | Time vector for response                                     | [1xM]   | load_stim_resps_from_baphy.m |
  | X{}.dat.().raw_isi         | Raw inter-spike intervals                                    |         |                              |
  | X{}.dat.().pp_stim         | Preprocessed stim                                            |         |                              |
  | X{}.dat.().ds_stim         | Downsampled, preprocessed stim                               |         |                              |
  | X{}.dat.().ds_resp         | Downsampled, preprocessed response                           |         |                              |
  | X{}.dat.().ds_respavg      | Downsampled, preprocessed histogram                          |         |                              |
  | X{}.dat.().lf_stim         | Linear filtered stimulus                                     |         |                              |
  | X{}.dat.().nl_stim         | Nonlinearly scaled stimulus                                  |         |                              |
  | X{}.dat.().pred            | Sum of the nonlinear stimuli; ie the prediction of the model |         |                              |
  | ...                        |                                                              |         |                              |
  |----------------------------+--------------------------------------------------------------+---------+------------------------------|

  In the above, dimensions are indicated with
        S = sound stimulus index #
        R = repetition index #
        N = Time index at the sampling rate of the stimulus. 
        M = Time index at the sampling rate of the response
        T = Time index in downsampled frequency
        F = Preprocessing index #

* How does it work?
** EVALUATION
   Essentially, there is a chain of function calls, with the output of one function pushed onto the inputs of the next.
   XXX{i+1} = STACK{i}.fn evaluated with data XXX{i}
** INVALIDATION
   If any intermediate parameter struct is modified, then it erases all XXX cells after it and the computation must recommence from that point. (I think continuation-passing-style would work well here, if such a thing were possible in matlab.)
** DIFFERENT TREES
   If you need to do different 'branches' of computation, you can store the current computation STACK and save them.
** MODULE LOADING
   The only functions available are isted in the "modules" directory, which is read ONCE, at startup. (or if you click 'refresh modules')
   They are only available from the popup selection when their ready_pred() function returns a true. 
** EDITING
   The "params" struct is GUI editable in much the same way that other things are.  
** GRAPHING
   Each module has (multiple) associated graphing functions which cann be seleceted via a dropdown
** ERROR HANDLING
   Whenever you load or run a user-loadable function, you put a try-catch block around it. 
** SAVING AND LOADING
   When you want to save a model, just save the STACK data structure somewhere along with the GIT hash tag and initial data. Data from that point can always be reconstructed.
   When you want to load a model, loop through the STACK structure, starting from the first data X, and reconstruct the data as you go along.
** OPTIMIZATION PACK/UNPACK
   PACK goes through the STACK sequentially, pulling out any args with a FIT checkbox (and returns a vector)
   UNPACK goes through the STACK sequentially, pushing in any args with a FIT checkbox (accepts a vector as the input)
   During optimization, all controls must be disabled to avoid invalidation problems?
** OPTIMIZATION PERFORMANCE METRIC, TERMINATION, SAMPLING
   These are not part of the model explicitly. 
   Instead, they run at the END of the function tree's execution to determine the score
   They have their own error graphs?
   I'm not interested in making their data directly viewable.

* Allowed Dimensions: How should can we accomodate the later addition of extra dimensions in the future, such as behavioral characteristics?
  Right now we have:
  1. StimFile               (Which is not indexed, but uses a keyword)
  2. Stimulus # 
  3. Value at time
  4. Repetition #
  5. Preprocessor Index #   (Because preprocessing may have multiple dimensions)
  In the future, we may have more. 
  The only way I can think about allowing multiple dimensions to vary arbitrarily would be to either:
  A) Somehow keep track of their numerical indexes as you go along, using a struct
  B) Avoid numerical indexes and use struct arrays or cell arrays everywhere? 
  Overall, option A sounds like the more efficient choice

* Tricky things:
  We may need to do an iteration procedure that treats one part of the model (IE, Linear FIR filters) differently from a nonlinear part (In my opinion, this is just a special case sampler)
  If you modify a function after starting up narf_gui, what will happen? (Right now, changes to the pretty-name and params will not be altered without restarting narf_gui, however if you fix the function itself then that is fine.)

* Issues for Stephen :
  1. Where is 'repetitions' visible? The closest thing I see is the 'Ref_Subsets' field returned in the 'parms' struct by 'dbReadData'

* Possible refactoring
  1. Data ordering is perhaps nonstandard, since we need filter(B,A,X,[],2) instead of filter(B,A,X);
  2. Should PREFILTEREDSTIM be a 3D matrix, or is it more convenient to use as a mixture of cell array and 2H matrices.? 
     STIM [30x400000] (30 tones with 400000 samples in time each)
     RESP [30x400000x3] (3 reps)
     PREFILTEREDSTIM{numoffilters} and under each cell [30x400000]
  3.  Rewrite of dbchooserawfile() because it's so damn useful for selecting a file, but let's make it work for multiple stimulus files
      (Should also display well, site and have selectors for channel, unit, etc
  4. Use squeeze() to remove unneeded dimensions from a matrix.
  5. Why is it 'stimpath' and 'stimfile' but 'path' and 'respfile'. it should be 'resppath'?
  7. Why is loadspikeraster the only thing that cares about the 'options' struct?
  8. Where should the line be drawn between analysis in the DB, partitionining things for your search within the DB, holding out data, etc?

* CODE TO REVIEW
  - [X] cellxcmaster('por012c-b1',238); % intelligently performs batch analysis 238 on cellid 'por012c-b1'
  - [ ] After the execution of the above, 'params' contains the details of how the analysis was performed.
  - [ ] params.resploadparms{1} is a way of getting
  - [ ] params.respfiles gives a list of the files being used during the analysis
  - [ ] dbget('sBatch', 238); % Returns details about which experiment is actually being performed
  - [ ] [cellfiledata, times, ...] = cellfiletimes()      % Note that times contains important info about the training set/test set split, such as the fitting method used?
  - [ ] xcloadfiles      % Performs analysis on multiple files, queries from the database
  - [X] xcloadstimresp   % A cleaner, gentler version of the previous file that is probably what I should base my analysis off of. 
  - [X] meska_pca()                              Used for doing the spike sorting, the front end. 
  - [ ] RemoteAnalysis/boost_online.m
  - [ ] Utilities/cacheevpspikes.m
  - [X] cellDB/dbchooserawfile.m
  - [X] Config/lbhb/BaphyMainGuiItems.m  has some hard-coded defaults for the GUI

* LUXURY TODO
  - [ ] make raw/stimulus response have two dropdowns to pick out colorbar thresholds for easier visualization
  - [ ]  Add a filter that processess phase information from a stimulus, not just the magnitude
  - [ ] Write a function which swaps out the GS into the BACKGROUND so you can 'hold' a model as a reference and play around with other settings, and see the results graphically by switching back and forth.
  - [ ] Write dbchoosecellfiles()
  - [ ] Use inter_curve_v3 to interactively make FIR things
  - [ ] Try adding color to histograms and scatter plots
  - [ ] try improving contrast of various intensity plots
  - [ ] Add BIC or AIC to model comparison data
  - [ ] Optimization report card and status information logged
  - [ ] Take the STRF of a model, not of the data!
  - [ ] Analyze:  'dai020a-c2', 'mag009b-b1', 'dai008a-c1', 'mag007d-d1'
  - [ ] Rank model fits and plot correlations

* KOANS
  The fastest way to climb a tall mountain is to accept that you must occasionally descend when you find yourself on the wrong path.
